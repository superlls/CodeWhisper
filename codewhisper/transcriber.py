"""
è½¬å½•å¼•æ“ - åŸºäº OpenAI Whisper çš„è½¬å½•æ ¸å¿ƒ
"""

import whisper
import torch
import re
from typing import Dict, Optional, Tuple, List

import numpy as np
from .dict_manager import DictionaryManager
from .prompt_engine import PromptEngine
from .utils import convert_to_simplified_chinese, normalize_zh_punctuation
from .console import info, debug


class CodeWhisper:
    """ä¸»è½¬å½•å¼•æ“"""

    def __init__(self, model_name: str = "medium", dict_path: Optional[str] = None):
        """
         CodeWhisper åˆå§‹åŒ–ï¼ŒåŒæ—¶é¢„åŠ è½½å­—å…¸çš„ç‰¹å®šæœ¯è¯­å¹¶å°†å…¶æ„å»ºä¸ºæç¤ºè¯å–‚ç»™Whisperè¿›è¡Œé¢„çƒ­ï¼›æ¨¡å‹é»˜è®¤medium
        Args:
            model_name: Whisper æ¨¡å‹ (tiny, base, small, medium, large)
            dict_path: è‡ªå®šä¹‰å­—å…¸è·¯å¾„ï¼Œæ”¯æŒåç»­æ‹“å±•todo
        """
        info(f"ğŸ“¦ Whisper æ¨¡å‹: {model_name}")

        # æ˜¾å¼è®¾å®šè®¾å¤‡ä¸ç²¾åº¦ï¼šä¼˜å…ˆä½¿ç”¨ NVIDIA CUDAï¼Œå…¶æ¬¡å›é€€ CPU
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        info(f"ğŸ§  æ¨ç†è®¾å¤‡: {self.device} (CPU å°†ä½¿ç”¨ FP32)")

        # openai-whisper ä¼šåœ¨ CUDA ä¸Šè‡ªåŠ¨ä½¿ç”¨ fp16ï¼Œåœ¨ CPU ä¸Šç”¨ fp32
        self.model = whisper.load_model(model_name, device=self.device)
        self.model_name = model_name

        debug("ğŸ“š åŠ è½½å­—å…¸ç®¡ç†å™¨")
        self.dict_manager = DictionaryManager(dict_path)

        debug("ğŸš€ åŠ è½½æ™ºèƒ½æç¤ºè¯å¼•æ“")
        self.prompt_engine = PromptEngine()

        # ä½¿ç”¨æ–°çš„ PromptEngine æ„å»ºæç¤ºè¯
        self.programmer_prompt = self.prompt_engine.build_prompt()
        info(f"ğŸ’¡ å½“å‰æç¤ºè¯: {self.programmer_prompt}")

        info("âœ… CodeWhisper åˆå§‹åŒ–å®Œæˆ")

    def _audio_level_stats(self, audio_file: str) -> Tuple[float, float, float]:
        """
        è¯»å–éŸ³é¢‘å¹¶è®¡ç®—å¼ºåº¦ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºå¿«é€Ÿåˆ¤æ–­â€œå‡ ä¹é™éŸ³â€çš„è¾“å…¥ã€‚

        Returns:
            (duration_seconds, rms, peak)
        """
        try:
            audio = whisper.load_audio(audio_file)
        except Exception:
            # è¯»å–å¤±è´¥æ—¶ä¸åšé™éŸ³åˆ¤å®šï¼ˆé¿å…è¯¯åˆ¤ç›´æ¥è·³è¿‡è½¬å½•ï¼‰
            return -1.0, 0.0, 0.0

        if audio is None or len(audio) == 0:
            return 0.0, 0.0, 0.0

        duration_seconds = float(len(audio) / whisper.audio.SAMPLE_RATE)
        rms = float(np.sqrt(np.mean(np.square(audio), dtype=np.float64)))
        peak = float(np.max(np.abs(audio)))
        return duration_seconds, rms, peak

    def _looks_like_repetition_loop(self, text: str, max_repeat: int = 10) -> bool:
        """
        æ£€æµ‹æ˜æ˜¾çš„â€œå¾ªç¯é‡å¤â€å¹»è§‰ï¼ˆå¸¸è§äºé™éŸ³/ä½è´¨é‡éŸ³é¢‘ï¼‰ã€‚

        ç›®æ ‡æ˜¯è¿‡æ»¤æ‰æç«¯æƒ…å†µï¼šæŸä¸ªè¯/å­—ç¬¦/çŸ­è¯­è¿ç»­é‡å¤å¾ˆå¤šæ¬¡ã€‚
        """
        if not text:
            return False

        normalized = re.sub(r"\s+", " ", text.strip())
        if not normalized:
            return False

        # 1) æŒ‰ç©ºæ ¼åˆ†è¯ï¼šæ£€æµ‹è¿ç»­ç›¸åŒè¯çš„è¶…é•¿ runï¼ˆæ›´é€‚ç”¨äºè‹±æ–‡/å¤¹æ‚è‹±æ–‡ï¼‰
        words = [w for w in normalized.split(" ") if w]
        if len(words) >= max_repeat:
            run = 1
            for idx in range(1, len(words)):
                if words[idx] == words[idx - 1]:
                    run += 1
                    if run >= max_repeat:
                        return True
                else:
                    run = 1

        # 2) ä¸­æ–‡å¸¸è§æ˜¯æ— ç©ºæ ¼è¾“å‡ºï¼šå»é™¤æ ‡ç‚¹/ç©ºç™½ååšå­—ç¬¦ä¸çŸ­è¯­é‡å¤æ£€æµ‹
        compact = re.sub(r"[\\sï¼Œã€‚ï¼ï¼Ÿ,.!?:;ï¼›ã€ã€‘ã€\\[\\]()ï¼ˆï¼‰\"'â€œâ€â€˜â€™â€”â€¦Â·]+", "", normalized)
        if len(compact) < max_repeat:
            return False

        # 2.1) å•å­—ç¬¦é‡å¤ï¼ˆå¦‚ â€œå•Šå•Šå•Šå•Š...â€ï¼‰
        if re.search(rf"(.)\\1{{{max_repeat - 1},}}", compact):
            return True

        # 2.2) çŸ­è¯­é‡å¤ï¼ˆå¦‚ â€œè°¢è°¢è§‚çœ‹è°¢è°¢è§‚çœ‹...â€ï¼‰
        # å°è¯• 2~10 å­—ç¬¦çš„çŸ­ç‰‡æ®µï¼Œé¿å…è¿‡äºæ˜‚è´µ
        for unit_len in range(2, 11):
            if len(compact) < unit_len * max_repeat:
                continue
            if re.search(rf"(.{{{unit_len}}})\\1{{{max_repeat - 1},}}", compact):
                return True

        return False

    def _filter_hallucinated_segments(
        self,
        segments: List[dict],
        *,
        max_repeat: int = 10,
        no_speech_prob_threshold: float = 0.8,
        avg_logprob_threshold: float = -0.8,
        compression_ratio_threshold: float = 2.4,
    ) -> List[dict]:
        """
        åœ¨ Whisper è¾“å‡ºååšä¸€æ¬¡è½»é‡è¿‡æ»¤ï¼Œå‰”é™¤æ˜æ˜¾é™éŸ³/ä¹±ç /é‡å¤å¾ªç¯æ®µã€‚

        - no_speech_prob é«˜ä¸” avg_logprob ä½ï¼šå¸¸è§é™éŸ³å¹»è§‰
        - compression_ratio è¿‡é«˜ï¼šå¸¸è§é‡å¤/ä¹±ç 
        - æ–‡æœ¬å‡ºç°æ˜æ˜¾å¾ªç¯é‡å¤ï¼šå¸¸è§â€œå¡ä½å¼â€å¹»è§‰
        """
        kept: List[dict] = []
        for seg in segments or []:
            text = (seg.get("text") or "").strip()
            if not text:
                continue

            no_speech_prob = float(seg.get("no_speech_prob", 0.0) or 0.0)
            avg_logprob = float(seg.get("avg_logprob", 0.0) or 0.0)
            compression_ratio = float(seg.get("compression_ratio", 0.0) or 0.0)

            # å‚è€ƒ whisper çš„é™éŸ³è·³è¿‡é€»è¾‘ï¼šno_speech_prob é«˜ä¸” logprob ä½æ—¶åˆ¤ä¸ºé™éŸ³
            if no_speech_prob >= no_speech_prob_threshold and avg_logprob <= avg_logprob_threshold:
                continue

            # é‡å¤/ä¹±ç è¿‡æ»¤
            if compression_ratio_threshold is not None and compression_ratio > compression_ratio_threshold:
                continue

            # å¾ªç¯é‡å¤è¿‡æ»¤
            if self._looks_like_repetition_loop(text, max_repeat=max_repeat):
                continue

            kept.append(seg)

        return kept

    def _remove_prompt_prefix(self, text: str) -> str:
        """
        è¿‡æ»¤æ‰è½¬å½•ç»“æœä¸­çš„æç¤ºè¯å‰ç¼€

        Whisper åœ¨é™éŸ³æˆ–éŸ³è´¨å·®æ—¶ï¼Œå¯èƒ½æŠŠ initial_prompt å½“æˆè½¬å½•ç»“æœè¾“å‡º
        """
        if not text:
            return text

        # è·å–æç¤ºè¯å‰ç¼€
        prompt_prefix = self.prompt_engine.config.get("prompt_prefix", "è®¡ç®—æœºè¡Œä¸šä»ä¸šè€…ï¼š")

        # å¦‚æœè½¬å½•ç»“æœä»¥æç¤ºè¯å‰ç¼€å¼€å¤´ï¼Œç§»é™¤å®ƒ
        if text.startswith(prompt_prefix):
            text = text[len(prompt_prefix):].strip()
            # å¦‚æœå‰©ä½™å†…å®¹ä¹Ÿæ˜¯æç¤ºè¯çš„ä¸€éƒ¨åˆ†ï¼ˆæœ¯è¯­åˆ—è¡¨ï¼‰ï¼Œå¯èƒ½æ•´ä¸ªéƒ½æ˜¯å¹»è§‰
            # æ£€æŸ¥æ˜¯å¦åªå‰©ä¸‹æœ¯è¯­å’Œæ ‡ç‚¹
            if self._is_only_prompt_content(text):
                return ""

        return text

    def _is_only_prompt_content(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åªåŒ…å«æç¤ºè¯å†…å®¹ï¼ˆæœ¯è¯­åˆ—è¡¨ï¼‰"""
        if not text:
            return True

        # ç§»é™¤å¸¸è§åˆ†éš”ç¬¦å’Œæ ‡ç‚¹
        cleaned = text.replace("ã€", "").replace("ï¼Œ", "").replace("ã€‚", "").replace(" ", "")

        # è·å–æ‰€æœ‰æœ¯è¯­
        all_terms = set(self.prompt_engine.base_dict)
        for term_info in self.prompt_engine.user_dict:
            all_terms.add(term_info.get("term", ""))

        # æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬æ˜¯å¦å…¨éƒ¨ç”±æœ¯è¯­ç»„æˆ
        remaining = cleaned
        for term in sorted(all_terms, key=len, reverse=True):
            remaining = remaining.replace(term, "")

        # å¦‚æœå‰©ä½™å†…å®¹ä¸ºç©ºæˆ–å¾ˆçŸ­ï¼Œè¯´æ˜å…¨æ˜¯æœ¯è¯­
        return len(remaining) <= 2

    def transcribe(
        self,
        audio_file: str,
        language: Optional[str] = "zh",
        fix_programmer_terms: bool = True,
        verbose: bool = True,
        temperature: float = 0.0,
        hallucination_filter: bool = True,
        silence_rms_threshold: float = 0.002,
        silence_peak_threshold: float = 0.02,
    ) -> Dict:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç  (é»˜è®¤zhä¸­æ–‡æ¨¡å‹)
            fix_programmer_terms: æ˜¯å¦ä¿®æ­£ç¨‹åºå‘˜æœ¯è¯­é»˜è®¤ä¸ºTrue
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ é»˜è®¤ä¸ºTrue (æ‰“å°è¾“å‡ºçŠ¶æ€ã€æç¤ºè¯åŠ è½½ã€ç¹ç®€è½¬æ¢ã€æœ¯è¯­ä¿®æ­£ç­‰æ­¥éª¤)
            temperature: æ§åˆ¶æ¨¡å‹çš„â€œéšæœºæ€§â€ï¼ŒèŒƒå›´é€šå¸¸åœ¨0â€”1ã€‚é»˜è®¤ä¸º0ï¼Œæ•°å€¼è¶Šé«˜ï¼Œè¾“å‡ºè¶Šæœ‰éšæœºæ€§ï¼ˆä¸æ¨èç”¨äºè¯­éŸ³è½¬å½•ï¼‰
            hallucination_filter: æ˜¯å¦å¯ç”¨å¹»è§‰/é‡å¤è¿‡æ»¤ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            silence_rms_threshold: é™éŸ³ RMS é˜ˆå€¼ï¼ˆè¶Šå¤§è¶Šæ¿€è¿›ï¼‰
            silence_peak_threshold: é™éŸ³ Peak é˜ˆå€¼ï¼ˆè¶Šå¤§è¶Šæ¿€è¿›ï¼‰


        Returns:
            åŒ…å«è½¬å½•ç»“æœçš„å­—å…¸
        """
        if verbose:
            debug(f"ğŸ™ï¸ è½¬å½•ä¸­ {audio_file} (è¯­è¨€: {language})")

        # å¿«é€Ÿé™éŸ³åˆ¤æ–­ï¼šé¿å…é™éŸ³è¾“å…¥è§¦å‘ Whisper äº§ç”Ÿâ€œé‡å¤å¹»è§‰â€
        if hallucination_filter:
            duration_seconds, rms, peak = self._audio_level_stats(audio_file)
            if verbose:
                debug(f"ğŸ”‡ éŸ³é¢‘å¼ºåº¦: æ—¶é•¿={duration_seconds:.2f}s, rms={rms:.5f}, peak={peak:.5f}")

            # duration_seconds < 0 è¡¨ç¤ºæ— æ³•è¯»å–éŸ³é¢‘ï¼Œè·³è¿‡é™éŸ³åˆ¤æ–­
            if duration_seconds == 0.0:
                if verbose:
                    debug("â­ï¸ éŸ³é¢‘ä¸ºç©ºï¼Œè·³è¿‡è½¬å½•")
                return {
                    "text": "",
                    "segments": [],
                    "language": language,
                    "_skipped_reason": "empty_audio",
                }

            if duration_seconds > 0.0 and (rms < silence_rms_threshold and peak < silence_peak_threshold):
                if verbose:
                    debug("â­ï¸ æ£€æµ‹åˆ°å‡ ä¹é™éŸ³ï¼Œè·³è¿‡è½¬å½•")
                return {
                    "text": "",
                    "segments": [],
                    "language": language,
                    "_skipped_reason": "silence",
                }

        # è°ƒç”¨ Whisper è¿›è¡Œè½¬å½•ï¼ˆä½¿ç”¨åˆå§‹åŒ–æ—¶ç¼“å­˜çš„æç¤ºè¯ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œverbose=False æ˜¯æŒ‡ OpenAI çš„Whisper è‡ªèº«çš„è°ƒè¯•æ—¥å¿—ï¼ˆè§£ç è¿›åº¦ç­‰ï¼‰
        # è€Œç”¨æˆ·çš„ verbose å‚æ•°æ§åˆ¶çš„æ˜¯ CodeWhisper çš„è¿›åº¦æ—¥å¿—ï¼ˆä¸Šé¢çš„if verboseï¼‰
        result = self.model.transcribe(
            audio_file,
            language=language,
            initial_prompt=self.programmer_prompt,
            # openai-whisper æ–°ç‰ˆæœ¬ï¼šverbose=False ä¼šæ˜¾ç¤º tqdm è¿›åº¦æ¡ï¼›verbose=None æ‰ä¼šå®‰é™
            verbose=None,
            temperature=temperature,
            # é˜²æ­¢ Whisper å¹»è§‰é‡å¤ bug
            condition_on_previous_text=False,  # ç¦ç”¨å‰æ–‡ä¾èµ–ï¼Œå‡å°‘é‡å¤å¾ªç¯
            compression_ratio_threshold=2.4,   # å‹ç¼©æ¯”é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™è®¤ä¸ºæ˜¯é‡å¤/ä¹±ç 
            no_speech_threshold=0.6,           # é™éŸ³æ£€æµ‹é˜ˆå€¼ï¼Œå‡å°‘é™éŸ³æ®µå¹»è§‰
            # é¿å… CPU ä¸Š fp16 è­¦å‘Šå™ªéŸ³
            fp16=(self.device == "cuda"),
        )

        if verbose:
            debug("âœ… è½¬å½•å®Œæˆ")

        # è¿‡æ»¤æ‰æç¤ºè¯å‰ç¼€ï¼ˆWhisper å¹»è§‰é—®é¢˜ï¼šé™éŸ³æ—¶å¯èƒ½æŠŠ initial_prompt å½“æˆè½¬å½•ç»“æœï¼‰
        result["text"] = self._remove_prompt_prefix(result["text"])
        for segment in result.get("segments", []):
            segment["text"] = self._remove_prompt_prefix(segment.get("text", ""))

        # å°†ç¹ä½“è½¬æ¢ä¸ºç®€ä½“
        if verbose:
            debug("ğŸ§¹ è½¬æ¢ç¹ä½“ä¸ºç®€ä½“")

        result["text"] = convert_to_simplified_chinese(result["text"])
        for segment in result["segments"]:
            segment["text"] = convert_to_simplified_chinese(segment["text"])

        # è§„èŒƒåŒ–ä¸­æ–‡æ ‡ç‚¹ï¼ˆå¦‚è‹±æ–‡é€—å· -> ä¸­æ–‡é€—å·ï¼‰
        if language and language.lower().startswith("zh"):
            result["text"] = normalize_zh_punctuation(result["text"])
            for segment in result["segments"]:
                segment["text"] = normalize_zh_punctuation(segment["text"])

        # è¿‡æ»¤é™éŸ³/ä¹±ç /å¾ªç¯é‡å¤åˆ†æ®µï¼Œå‡å°‘â€œå¹»è§‰é‡å¤â€
        if hallucination_filter:
            filtered_segments = self._filter_hallucinated_segments(result.get("segments", []))
            if len(filtered_segments) != len(result.get("segments", [])) and verbose:
                debug(f"ğŸ§½ å¹»è§‰è¿‡æ»¤: {len(result.get('segments', []))} -> {len(filtered_segments)} æ®µ")
            result["segments"] = filtered_segments
            result["text"] = "".join([seg.get("text", "") for seg in filtered_segments]).strip()

            if language and language.lower().startswith("zh"):
                result["text"] = normalize_zh_punctuation(result["text"])

        # æ›¿æ¢æœ¯è¯­
        if fix_programmer_terms:
            if verbose:
                debug("ğŸ›  ä¿®æ­£ä¸ºå¼€å‘è€…æœ¯è¯­")

            # åªä¿®æ­£æ­£æ–‡æ–‡æœ¬ä¸€æ¬¡ï¼Œé¿å…é‡å¤ä¿®æ­£
            result["text"] = self.dict_manager.fix_text(result["text"], accumulate=False)

            if language and language.lower().startswith("zh"):
                result["text"] = normalize_zh_punctuation(result["text"])

        # å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯ï¼šæ£€æµ‹æ–‡æœ¬ä¸­å‡ºç°çš„æœ¯è¯­å¹¶æ›´æ–°ç”¨æˆ·æœ¯è¯­åº“
        if verbose:
            debug("ğŸ§  å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯")

        # æ–¹æ³•1ï¼šä»ä¿®æ­£è®°å½•ä¸­è·å–æœ¯è¯­ï¼ˆä¼˜å…ˆï¼Œæ›´ç²¾å‡†ï¼‰
        detected_terms = self.dict_manager.get_detected_terms_from_corrections()

        # æ–¹æ³•2ï¼šä»æœ€ç»ˆæ–‡æœ¬ä¸­æ£€æµ‹æœ¯è¯­ï¼ˆè¡¥å……ï¼‰
        detected_terms_from_text = self.dict_manager.detect_terms_in_text(result["text"])
        detected_terms.update(detected_terms_from_text)

        if detected_terms:
            if verbose:
                debug(f"  æ£€æµ‹åˆ°æœ¯è¯­: {', '.join(list(detected_terms)[:5])}{'...' if len(detected_terms) > 5 else ''}")
            # æ›´æ–°ç”¨æˆ·æœ¯è¯­åº“
            self.prompt_engine.update_user_terms(detected_terms)

            # é‡æ–°æ„å»ºæç¤ºè¯ï¼ˆä¸‹æ¬¡è½¬å½•ä½¿ç”¨ï¼‰
            self.programmer_prompt = self.prompt_engine.build_prompt()

        return result

    def get_supported_models(self) -> list:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return ["tiny", "base", "small", "medium", "large"]

    def get_dict_stats(self) -> Dict:
        """è·å–å­—å…¸ç»Ÿè®¡ä¿¡æ¯"""
        return self.dict_manager.get_stats()

    def get_dict_categories(self) -> Dict:
        """è·å–å­—å…¸åˆ†ç±»ç»Ÿè®¡"""
        return self.dict_manager.list_categories()

    def get_prompt_stats(self) -> Dict:
        """è·å–æç¤ºè¯å¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        return self.prompt_engine.get_stats()
