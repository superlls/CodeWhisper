"""
è½¬å½•å¼•æ“ - åŸºäº faster-whisper (CTranslate2) çš„è½¬å½•æ ¸å¿ƒ
"""

import platform
from typing import Dict, Optional, Tuple

import torch
from faster_whisper import WhisperModel

from .dict_manager import DictionaryManager
from .prompt_engine import PromptEngine
from .utils import convert_to_simplified_chinese


class CodeWhisper:
    """ä¸»è½¬å½•å¼•æ“"""

    def __init__(self, model_name: str = "medium", dict_path: Optional[str] = None):
        """
         CodeWhisper åˆå§‹åŒ–ï¼ŒåŒæ—¶é¢„åŠ è½½å­—å…¸çš„ç‰¹å®šæœ¯è¯­å¹¶å°†å…¶æ„å»ºä¸ºæç¤ºè¯å–‚ç»™Whisperè¿›è¡Œé¢„çƒ­ï¼›æ¨¡å‹é»˜è®¤medium
        Args:
            model_name: Whisper æ¨¡å‹ (tiny, base, small, medium, large)
            dict_path: è‡ªå®šä¹‰å­—å…¸è·¯å¾„ï¼Œæ”¯æŒåç»­æ‹“å±•todo
        """
        self.model_name = model_name
        self.device = "cpu"
        self.compute_type = "int8_float16"

        print(f"ğŸ“¦ åŠ è½½ Whisper æ¨¡å‹: {model_name}")
        self.model = self._load_model(model_name)

        print(f"ğŸ“š åŠ è½½å­—å…¸ç®¡ç†å™¨")
        self.dict_manager = DictionaryManager(dict_path)

        print(f"ğŸš€ åŠ è½½æ™ºèƒ½æç¤ºè¯å¼•æ“")
        self.prompt_engine = PromptEngine()

        # ä½¿ç”¨æ–°çš„ PromptEngine æ„å»ºæç¤ºè¯
        self.programmer_prompt = self.prompt_engine.build_prompt()
        print(f"ğŸ’¡ å½“å‰æç¤ºè¯ {self.programmer_prompt}")

        print(f"âœ…CodeWhisper åˆå§‹åŒ–å®Œæˆ\n")

    def _select_device_and_precision(self) -> Tuple[str, str]:
        """
        æ ¹æ®ç¡¬ä»¶ç¯å¢ƒé€‰æ‹© device ä¸ compute_typeã€‚
        ä¼˜å…ˆä½¿ç”¨ NVIDIA GPUï¼›Mac è§†ä¸º CPUï¼›CPU é»˜è®¤ int8_float16ï¼Œå†…å­˜ä¸è¶³å¯é€€åˆ° int8ã€‚
        """
        system = platform.system()

        if torch.cuda.is_available():
            return "cuda", "float16"

        # Apple Silicon ä¹Ÿèµ° CPU è·¯å¾„
        if system == "Darwin":
            return "cpu", "int8_float16"

        # é»˜è®¤ CPU
        return "cpu", "int8_float16"

    def _load_model(self, model_name: str) -> WhisperModel:
        """åŠ è½½ faster-whisper æ¨¡å‹ï¼Œå¿…è¦æ—¶é™çº§ç²¾åº¦ä»¥èŠ‚çœå†…å­˜ã€‚"""
        device, compute_type = self._select_device_and_precision()
        self.device = device
        self.compute_type = compute_type

        print(f"ğŸ–¥ï¸ è®¾å¤‡: {device}, ç²¾åº¦: {compute_type}")
        try:
            return WhisperModel(
                model_name,
                device=device,
                compute_type=compute_type,
            )
        except Exception as e:
            # CPU å†…å­˜ä¸è¶³æ—¶å°è¯•é™çº§åˆ° int8
            if device == "cpu" and compute_type == "int8_float16":
                fallback_compute = "int8"
                print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•é™çº§ç²¾åº¦ä¸º {fallback_compute}: {e}")
                try:
                    self.compute_type = fallback_compute
                    return WhisperModel(
                        model_name,
                        device=device,
                        compute_type=fallback_compute,
                    )
                except Exception as e2:
                    print(f"âŒ é™çº§åŠ è½½ä»å¤±è´¥: {e2}")
                    raise
            raise

    def transcribe(
        self,
        audio_file: str,
        language: Optional[str] = "zh",
        fix_programmer_terms: bool = True,
        verbose: bool = True,
        temperature: float = 0.0,
    ) -> Dict:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç  (é»˜è®¤zhä¸­æ–‡æ¨¡å‹)
            fix_programmer_terms: æ˜¯å¦ä¿®æ­£ç¨‹åºå‘˜æœ¯è¯­é»˜è®¤ä¸ºTrue
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ é»˜è®¤ä¸ºTrue (æ‰“å°è¾“å‡ºçŠ¶æ€ã€æç¤ºè¯åŠ è½½ã€ç¹ç®€è½¬æ¢ã€æœ¯è¯­ä¿®æ­£ç­‰æ­¥éª¤)
            temperature: æ§åˆ¶æ¨¡å‹çš„â€œéšæœºæ€§â€ï¼ŒèŒƒå›´é€šå¸¸åœ¨0â€”1ã€‚é»˜è®¤ä¸º0ï¼Œæ•°å€¼è¶Šé«˜ï¼Œè¾“å‡ºè¶Šæœ‰éšæœºæ€§ï¼ˆä¸æ¨èç”¨äºè¯­éŸ³è½¬å½•ï¼‰


        Returns:
            åŒ…å«è½¬å½•ç»“æœçš„å­—å…¸
        """
        if verbose:
            print(f"ğŸ™ï¸ è½¬å½•ä¸­ {audio_file} (è¯­è¨€: {language})")

        try:
            segments, info = self.model.transcribe(
                audio_file,
                language=language,
                initial_prompt=self.programmer_prompt,
                beam_size=1,  # ä¼˜å…ˆä½å»¶è¿Ÿ
                temperature=temperature,
            )
        except Exception as e:
            print(f"âŒ è½¬å½•å¤±è´¥: {e}")
            raise

        if verbose:
            print(f"âœ…è½¬å½•å®Œæˆ")

        # èšåˆæ–‡æœ¬ä¸æ®µä¿¡æ¯ï¼Œä¿æŒä¸åŸ Whisper è¾“å‡ºç»“æ„å…¼å®¹
        segment_list = []
        texts = []
        for idx, seg in enumerate(segments):
            seg_text = seg.text.strip()
            texts.append(seg_text)
            segment_list.append({
                "id": idx,
                "seek": 0,
                "start": seg.start,
                "end": seg.end,
                "text": seg_text,
                "tokens": getattr(seg, "tokens", []),
                "temperature": temperature,
                "avg_logprob": getattr(seg, "avg_logprob", 0.0),
                "compression_ratio": getattr(seg, "compression_ratio", 0.0),
                "no_speech_prob": getattr(seg, "no_speech_prob", 0.0),
                "logprob": getattr(seg, "avg_logprob", 0.0),
            })

        result = {
            "text": " ".join(texts).strip(),
            "segments": segment_list,
            "language": getattr(info, "language", language),
        }

        # å°†ç¹ä½“è½¬æ¢ä¸ºç®€ä½“
        if verbose:
            print(f"ğŸ§¹ è½¬æ¢ç¹ä½“ä¸ºç®€ä½“")

        result["text"] = convert_to_simplified_chinese(result["text"])
        for segment in result["segments"]:
            segment["text"] = convert_to_simplified_chinese(segment["text"])

        # æ›¿æ¢æœ¯è¯­
        if fix_programmer_terms:
            if verbose:
                print(f"ğŸ›  ä¿®æ­£ä¸ºå¼€å‘è€…æœ¯è¯­")

            # åªä¿®æ­£æ­£æ–‡æ–‡æœ¬ä¸€æ¬¡ï¼Œé¿å…é‡å¤ä¿®æ­£
            result["text"] = self.dict_manager.fix_text(result["text"], accumulate=False)

        # å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯ï¼šæ£€æµ‹æ–‡æœ¬ä¸­å‡ºç°çš„æœ¯è¯­å¹¶æ›´æ–°ç”¨æˆ·æœ¯è¯­åº“
        if verbose:
            print(f"ğŸ§  å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯")

        # æ–¹æ³•1ï¼šä»ä¿®æ­£è®°å½•ä¸­è·å–æœ¯è¯­ï¼ˆä¼˜å…ˆï¼Œæ›´ç²¾å‡†ï¼‰
        detected_terms = self.dict_manager.get_detected_terms_from_corrections()

        # æ–¹æ³•2ï¼šä»æœ€ç»ˆæ–‡æœ¬ä¸­æ£€æµ‹æœ¯è¯­ï¼ˆè¡¥å……ï¼‰
        detected_terms_from_text = self.dict_manager.detect_terms_in_text(result["text"])
        detected_terms.update(detected_terms_from_text)

        if detected_terms:
            if verbose:
                print(f"  æ£€æµ‹åˆ°æœ¯è¯­: {', '.join(list(detected_terms)[:5])}{'...' if len(detected_terms) > 5 else ''}")
            # æ›´æ–°ç”¨æˆ·æœ¯è¯­åº“
            self.prompt_engine.update_user_terms(detected_terms)

            # é‡æ–°æ„å»ºæç¤ºè¯ï¼ˆä¸‹æ¬¡è½¬å½•ä½¿ç”¨ï¼‰
            self.programmer_prompt = self.prompt_engine.build_prompt()

        return result

    def get_supported_models(self) -> list:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return ["tiny", "base", "small", "medium", "large"]

    def get_dict_stats(self) -> Dict:
        """è·å–å­—å…¸ç»Ÿè®¡ä¿¡æ¯"""
        return self.dict_manager.get_stats()

    def get_dict_categories(self) -> Dict:
        """è·å–å­—å…¸åˆ†ç±»ç»Ÿè®¡"""
        return self.dict_manager.list_categories()

    def get_prompt_stats(self) -> Dict:
        """è·å–æç¤ºè¯å¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        return self.prompt_engine.get_stats()
