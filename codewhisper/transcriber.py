"""
è½¬å½•å¼•æ“ - åŸºäº OpenAI Whisper çš„è½¬å½•æ ¸å¿ƒ
"""

import whisper
import torch
from typing import Dict, Optional
from .dict_manager import DictionaryManager
from .prompt_engine import PromptEngine
from .utils import convert_to_simplified_chinese


class CodeWhisper:
    """ä¸»è½¬å½•å¼•æ“"""

    def __init__(self, model_name: str = "medium", dict_path: Optional[str] = None):
        """
         CodeWhisper åˆå§‹åŒ–ï¼ŒåŒæ—¶é¢„åŠ è½½å­—å…¸çš„ç‰¹å®šæœ¯è¯­å¹¶å°†å…¶æ„å»ºä¸ºæç¤ºè¯å–‚ç»™Whisperè¿›è¡Œé¢„çƒ­ï¼›æ¨¡å‹é»˜è®¤medium
        Args:
            model_name: Whisper æ¨¡å‹ (tiny, base, small, medium, large)
            dict_path: è‡ªå®šä¹‰å­—å…¸è·¯å¾„ï¼Œæ”¯æŒåç»­æ‹“å±•todo
        """
        print(f"ğŸ“¦ åŠ è½½ Whisper æ¨¡å‹: {model_name}")

        # æ˜¾å¼è®¾å®šè®¾å¤‡ä¸ç²¾åº¦ï¼šä¼˜å…ˆä½¿ç”¨ NVIDIA CUDAï¼Œå…¶æ¬¡å›é€€ CPU
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"  è®¾å¤‡é€‰æ‹©: device={device},å¦‚æ‚¨ä½¿ç”¨CUDAæŠ¥ `CUBLAS_STATUS_ALLOC_FAILED` ï¼Œè¯·æ”¹ç”¨æ›´å°æ¨¡å‹ï¼ˆbase/smallï¼‰")

        # openai-whisper ä¼šåœ¨ CUDA ä¸Šè‡ªåŠ¨ä½¿ç”¨ fp16ï¼Œåœ¨ CPU ä¸Šç”¨ fp32
        self.model = whisper.load_model(model_name, device=device)
        self.model_name = model_name

        print(f"ğŸ“š åŠ è½½å­—å…¸ç®¡ç†å™¨")
        self.dict_manager = DictionaryManager(dict_path)

        print(f"ğŸš€ åŠ è½½æ™ºèƒ½æç¤ºè¯å¼•æ“")
        self.prompt_engine = PromptEngine()

        # ä½¿ç”¨æ–°çš„ PromptEngine æ„å»ºæç¤ºè¯
        self.programmer_prompt = self.prompt_engine.build_prompt()
        print(f"ğŸ’¡ å½“å‰æç¤ºè¯ {self.programmer_prompt}")

        print(f"âœ…CodeWhisper åˆå§‹åŒ–å®Œæˆ\n")

    def transcribe(
        self,
        audio_file: str,
        language: Optional[str] = "zh",
        fix_programmer_terms: bool = True,
        verbose: bool = True,
        temperature: float = 0.0,
    ) -> Dict:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç  (é»˜è®¤zhä¸­æ–‡æ¨¡å‹)
            fix_programmer_terms: æ˜¯å¦ä¿®æ­£ç¨‹åºå‘˜æœ¯è¯­é»˜è®¤ä¸ºTrue
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ é»˜è®¤ä¸ºTrue (æ‰“å°è¾“å‡ºçŠ¶æ€ã€æç¤ºè¯åŠ è½½ã€ç¹ç®€è½¬æ¢ã€æœ¯è¯­ä¿®æ­£ç­‰æ­¥éª¤)
            temperature: æ§åˆ¶æ¨¡å‹çš„â€œéšæœºæ€§â€ï¼ŒèŒƒå›´é€šå¸¸åœ¨0â€”1ã€‚é»˜è®¤ä¸º0ï¼Œæ•°å€¼è¶Šé«˜ï¼Œè¾“å‡ºè¶Šæœ‰éšæœºæ€§ï¼ˆä¸æ¨èç”¨äºè¯­éŸ³è½¬å½•ï¼‰


        Returns:
            åŒ…å«è½¬å½•ç»“æœçš„å­—å…¸
        """
        if verbose:
            print(f"ğŸ™ï¸ è½¬å½•ä¸­ {audio_file} (è¯­è¨€: {language})")

        # è°ƒç”¨ Whisper è¿›è¡Œè½¬å½•ï¼ˆä½¿ç”¨åˆå§‹åŒ–æ—¶ç¼“å­˜çš„æç¤ºè¯ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œverbose=False æ˜¯æŒ‡ OpenAI çš„Whisper è‡ªèº«çš„è°ƒè¯•æ—¥å¿—ï¼ˆè§£ç è¿›åº¦ç­‰ï¼‰
        # è€Œç”¨æˆ·çš„ verbose å‚æ•°æ§åˆ¶çš„æ˜¯ CodeWhisper çš„è¿›åº¦æ—¥å¿—ï¼ˆä¸Šé¢çš„if verboseï¼‰
        result = self.model.transcribe(
            audio_file,
            language=language,
            initial_prompt=self.programmer_prompt,
            verbose=False,  # Whisper å†…éƒ¨æ—¥å¿—å…³é—­ï¼Œç”± CodeWhisper çš„verbose æ§åˆ¶å¤–éƒ¨æ—¥å¿—
            temperature=temperature
        )

        if verbose:
            print(f"âœ…è½¬å½•å®Œæˆ")

        # å°†ç¹ä½“è½¬æ¢ä¸ºç®€ä½“
        if verbose:
            print(f"ğŸ§¹ è½¬æ¢ç¹ä½“ä¸ºç®€ä½“")

        result["text"] = convert_to_simplified_chinese(result["text"])
        for segment in result["segments"]:
            segment["text"] = convert_to_simplified_chinese(segment["text"])

        # æ›¿æ¢æœ¯è¯­
        if fix_programmer_terms:
            if verbose:
                print(f"ğŸ›  ä¿®æ­£ä¸ºå¼€å‘è€…æœ¯è¯­")

            # åªä¿®æ­£æ­£æ–‡æ–‡æœ¬ä¸€æ¬¡ï¼Œé¿å…é‡å¤ä¿®æ­£
            result["text"] = self.dict_manager.fix_text(result["text"], accumulate=False)

        # å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯ï¼šæ£€æµ‹æ–‡æœ¬ä¸­å‡ºç°çš„æœ¯è¯­å¹¶æ›´æ–°ç”¨æˆ·æœ¯è¯­åº“
        if verbose:
            print(f"ğŸ§  å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯")

        # æ–¹æ³•1ï¼šä»ä¿®æ­£è®°å½•ä¸­è·å–æœ¯è¯­ï¼ˆä¼˜å…ˆï¼Œæ›´ç²¾å‡†ï¼‰
        detected_terms = self.dict_manager.get_detected_terms_from_corrections()

        # æ–¹æ³•2ï¼šä»æœ€ç»ˆæ–‡æœ¬ä¸­æ£€æµ‹æœ¯è¯­ï¼ˆè¡¥å……ï¼‰
        detected_terms_from_text = self.dict_manager.detect_terms_in_text(result["text"])
        detected_terms.update(detected_terms_from_text)

        if detected_terms:
            if verbose:
                print(f"  æ£€æµ‹åˆ°æœ¯è¯­: {', '.join(list(detected_terms)[:5])}{'...' if len(detected_terms) > 5 else ''}")
            # æ›´æ–°ç”¨æˆ·æœ¯è¯­åº“
            self.prompt_engine.update_user_terms(detected_terms)

            # é‡æ–°æ„å»ºæç¤ºè¯ï¼ˆä¸‹æ¬¡è½¬å½•ä½¿ç”¨ï¼‰
            self.programmer_prompt = self.prompt_engine.build_prompt()

        return result

    def get_supported_models(self) -> list:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return ["tiny", "base", "small", "medium", "large"]

    def get_dict_stats(self) -> Dict:
        """è·å–å­—å…¸ç»Ÿè®¡ä¿¡æ¯"""
        return self.dict_manager.get_stats()

    def get_dict_categories(self) -> Dict:
        """è·å–å­—å…¸åˆ†ç±»ç»Ÿè®¡"""
        return self.dict_manager.list_categories()

    def get_prompt_stats(self) -> Dict:
        """è·å–æç¤ºè¯å¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        return self.prompt_engine.get_stats()
